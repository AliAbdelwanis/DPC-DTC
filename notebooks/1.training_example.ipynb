{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e8acaf",
   "metadata": {},
   "source": [
    "# DPC Torque Control — Training Example\n",
    "\n",
    "This notebook demonstrates the basic usage of the Differentiable predictive control (DPC) codebase\n",
    "and provides a minimal, end-to-end example that can be executed top-to-bottom.\n",
    "\n",
    "## Overview\n",
    "- **Goal:** Train a neural network policy to control PMSM torque.\n",
    "- **Method:** Differentiable predictive control (DPC)\n",
    "- **Output:** Trained policy network with convergence analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d6b2f",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "### Requirements\n",
    "1. Clone the repository from GitHub\n",
    "2. Install all dependencies listed in `requirements.txt`\n",
    "3. Ensure JAX is configured to use GPU (optional but recommended for performance)\n",
    "\n",
    "### Execution\n",
    "- Run all cells sequentially from top to bottom\n",
    "- Each cell depends on the previous ones having completed successfully\n",
    "- Total runtime: ~5 hours (depends on hardware and training configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca29c07",
   "metadata": {},
   "source": [
    "## Notebook Sections\n",
    "\n",
    "This notebook is organized into the following sections:\n",
    "\n",
    "1. **Setup & Dependencies** - Import required libraries and configure JAX\n",
    "2. **Motor Definition** - Initialize PMSM (Permanent Magnet Synchronous Motor) with physical parameters\n",
    "3. **Training Configuration** - Define neural network architecture, loss functions, and training hyperparameters\n",
    "4. **Trainer Initialization** - Create DPC trainer instance with configured components\n",
    "5. **Training Execution** - Train the policy network \n",
    "6. **Results Analysis** - Plot training losses and visualize convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609d42e",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies\n",
    "\n",
    "### Import External Libraries and Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import external dependencies for numerical computation, JAX framework, and visualization.\n",
    "\n",
    "Libraries used:\n",
    "- JAX/Equinox: Automatic differentiation and neural network primitives\n",
    "- NumPy: Numerical operations and array handling\n",
    "- Optax: Gradient-based optimization algorithms\n",
    "- Matplotlib: Data visualization\n",
    "- CasADi: Symbolic computation (optional, for OCP solver)\n",
    "\"\"\"\n",
    "\n",
    "# Core scientific computing\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# JAX ecosystem\n",
    "import jax\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "# Visualization and data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "\n",
    "# Utilities\n",
    "from functools import partial\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "\n",
    "# Symbolic computation (for OCP solver)\n",
    "import casadi as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2383486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure project root and add to Python path for local module imports.\n",
    "\n",
    "This allows importing from policy/, utils/, and visualization/ directories.\n",
    "\"\"\"\n",
    "\n",
    "# Add project root to Python path for local imports\n",
    "PROJECT_ROOT = Path().resolve().parents[0]\n",
    "sys.path.insert(0, str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import project-specific modules for motor simulation, policy training, and visualization.\n",
    "\n",
    "Components:\n",
    "- Motor Environment: PMSM physical simulator\n",
    "- Policy Training: DPC trainer and neural network architecture\n",
    "- Loss Functions: Multi-objective loss components for policy optimization\n",
    "- Utilities: Data generation, feature extraction, and visualization\n",
    "\"\"\"\n",
    "\n",
    "# Motor environment and simulation\n",
    "from exciting_environments.pmsm.pmsm_env import PMSM\n",
    "\n",
    "# Policy architecture and training\n",
    "from policy.policy_training import DPCTrainer\n",
    "from policy.networks import MLP\n",
    "from policy.data_generation import reset, generate_feasible, node_dat_gen_sin, featurize\n",
    "\n",
    "# Loss functions (6 component weighted loss)\n",
    "from policy.losses import (\n",
    "    ref_loss_fcn,                    # Torque reference tracking error\n",
    "    efficincy_loss_fcn,              # Copper loss minimization\n",
    "    posit_id_loss_fcn,               # Positive d-axis current constraint\n",
    "    idq_nom_loss_fcn,                # Nominal current operating point\n",
    "    idq_lim_loss,                    # Current limit constraint\n",
    "    idq_SS_loss                      # Steady-state error\n",
    ")\n",
    "\n",
    "# Diagnostics and visualization\n",
    "from policy.policy_training_diagnostics import plot_training_losses\n",
    "from visualization.style import set_plot_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure JAX and matplotlib for this notebook session.\n",
    "\n",
    "JAX Setup:\n",
    "- Detect available GPU devices\n",
    "- Set primary computation device (GPU if available, otherwise CPU)\n",
    "\n",
    "Matplotlib Setup:\n",
    "- Apply custom plot styling for consistent visualization\n",
    "\"\"\"\n",
    "\n",
    "# Configure JAX: use first available device (GPU preferred)\n",
    "gpus = jax.devices()\n",
    "jax.config.update(\"jax_default_device\", gpus[0])\n",
    "\n",
    "# Apply custom plot styling\n",
    "set_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f356d8f",
   "metadata": {},
   "source": [
    "## 2. Motor Definition\n",
    "\n",
    "### Initialize PMSM with Physical Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50112b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create PMSM (Permanent Magnet Synchronous Motor) environment instance.\n",
    "\n",
    "Motor: BRUSA (electric vehicle traction motor)\n",
    "Physical Parameters:\n",
    "- Pole pairs (p): 3\n",
    "- Stator resistance (r_s): 15 mΩ\n",
    "- D-axis inductance (l_d): 0.37 mH\n",
    "- Q-axis inductance (l_q): 1.2 mH\n",
    "- Permanent magnet flux (psi_p): 65.6 mH\n",
    "- Deadtime: 0 µs (ideal inverter)\n",
    "\n",
    "Configuration:\n",
    "- Batch size: 1 (single trajectory simulation)\n",
    "- Saturation: Disabled (linear motor model)\n",
    "- LUT: Look-up table motor characterization\n",
    "\"\"\"\n",
    "\n",
    "motor_env = PMSM(\n",
    "    LUT_motor_name=\"BRUSA\",\n",
    "    saturated=False,\n",
    "    batch_size=1,\n",
    "    control_state=[],\n",
    "    static_params={\n",
    "        \"p\": 3,                    # Pole pairs\n",
    "        \"r_s\": 15e-3,              # Stator resistance (Ω)\n",
    "        \"l_d\": 0.37e-3,            # D-axis inductance (H)\n",
    "        \"l_q\": 1.2e-3,             # Q-axis inductance (H)\n",
    "        \"psi_p\": 65.6e-3,          # Permanent magnet flux (Wb)\n",
    "        \"deadtime\": 0,             # Inverter deadtime (s)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51615a",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "### Define Neural Network Architecture and Loss Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure neural network policy architecture and training hyperparameters.\n",
    "\n",
    "Neural Network Architecture:\n",
    "- Input: 8 features (motor state: currents, speed, etc.)\n",
    "- Hidden layers: 3 × 128 units (fully-connected with activation)\n",
    "- Output: 2 actions (d-axis and q-axis voltage commands)\n",
    "- Framework: MLP (Multi-Layer Perceptron) with Equinox\n",
    "\n",
    "Optimization:\n",
    "- Optimizer: Adam with learning rate 1e-4\n",
    "- Batch size: 50 trajectories per gradient update\n",
    "- Training steps: 500000 gradient descent iterations\n",
    "\n",
    "Loss Function (6 weighted components):\n",
    "1. Reference tracking (weight: 1.0) - Follow desired torque\n",
    "2. Efficiency loss (weight: 0.008) - Minimize copper losses (I²R)\n",
    "3. Positive id constraint (weight: 0.0) - Encourage d-axis current direction\n",
    "4. Nominal current (weight: 0.0) - Penalize deviation from nominal operating point\n",
    "5. Current limit constraint (weight: 0.4) - Soft constraint on current magnitude\n",
    "6. Steady-state error (weight: 0.0) - Final state tracking error\n",
    "\"\"\"\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = np.random.randint(0, 2**3)\n",
    "jax_key = jax.random.PRNGKey(6)\n",
    "\n",
    "# Neural network architecture parameters\n",
    "layer_size = 128                   # Hidden layer width\n",
    "num_layers = 3                     # Number of hidden layers\n",
    "input_dim = 8                      # State observation dimension\n",
    "output_dim = 2                     # Action dimension (u_d, u_q)\n",
    "\n",
    "# Build MLP policy architecture: [input] → [128, 128, 128] → [output]\n",
    "policy_archit = [input_dim] + [layer_size for _ in range(num_layers)] + [output_dim]\n",
    "policy = MLP(policy_archit, key=jax_key)\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = optax.adam(1e-4)       # Adam optimizer with learning rate\n",
    "opt_state = optimizer.init(policy) # Initialize optimizer state\n",
    "\n",
    "# Loss functions (6 components for multi-objective optimization)\n",
    "loss_fcns = [\n",
    "    ref_loss_fcn,                  # Torque reference tracking\n",
    "    efficincy_loss_fcn,            # Efficiency (minimize copper loss)\n",
    "    posit_id_loss_fcn,             # Positive d-axis constraint\n",
    "    idq_nom_loss_fcn,              # Nominal current operating point\n",
    "    idq_lim_loss,                  # Current magnitude constraint\n",
    "    idq_SS_loss                    # Steady-state error\n",
    "]\n",
    "\n",
    "# Loss weights for each component (tuned for MTPC control)\n",
    "ieff = 0.008                       # Efficiency loss weight\n",
    "iL = 0.4                           # Current limit constraint weight\n",
    "loss_weights = [1.0, ieff, 0.0, 0.0, iL, 0.0]\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 50                    # Trajectories per batch\n",
    "train_steps = 500000                 # Total gradient descent iterations\n",
    "horizon = 60                       # Prediction/rollout horizon (timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fad578",
   "metadata": {},
   "source": [
    "## 4. Trainer Initialization\n",
    "\n",
    "### Create DPC Trainer with Configured Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create DPCTrainer instance that orchestrates the policy training process.\n",
    "\n",
    "DPCTrainer Configuration:\n",
    "- Manages batch generation, loss computation, and gradient updates\n",
    "- Handles trajectory sampling across motor operating points (speed/torque grid)\n",
    "- Applies analytical reference generation (AnalyticalRG) for reference signals\n",
    "- Computes multi-objective weighted loss and backpropagation\n",
    "\n",
    "Key Components:\n",
    "- reset_env: Reinitialize motor state at trajectory start\n",
    "- data_gen_sin: Single-data reference generator\n",
    "- gen_feas: Generate feasible reference currents and torques\n",
    "- featurize: Extract neural network input features from motor observations\n",
    "\"\"\"\n",
    "\n",
    "# Create trainer instance with all components\n",
    "trainer = DPCTrainer(\n",
    "    batch_size=batch_size,                        # Trajectories per gradient step\n",
    "    train_steps=train_steps,                      # Total training iterations\n",
    "    horizon_length=horizon,                       # Prediction horizon\n",
    "    reset_env=reset,                              # Environment reset function\n",
    "    data_gen_sin=node_dat_gen_sin,                # Reference trajectory generator\n",
    "    gen_feas=generate_feasible,                   # Feasible reference generator\n",
    "    featurize=featurize,                          # Feature extraction function\n",
    "    policy_optimizer=optimizer,                   # Gradient optimizer (Adam)\n",
    "    loss_fcns=loss_fcns,                          # 6-component loss functions\n",
    "    loss_weights=loss_weights,                    # Loss weights vector\n",
    ")\n",
    "\n",
    "# Initialize random keys for batch sampling (one per trajectory)\n",
    "# This enables deterministic but pseudo-random trajectory sampling\n",
    "keys = jax.vmap(jax.random.PRNGKey)(\n",
    "    np.random.randint(0, 2**31, size=(batch_size,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96d52f",
   "metadata": {},
   "source": [
    "## 5. Training Execution\n",
    "\n",
    "### Train Policy on PMSM Environment\n",
    "\n",
    "Progress is displayed via tqdm progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute policy training loop using DPCTrainer.\n",
    "\n",
    "This applies DPC over 'train_steps' iterations\n",
    "\n",
    "Returns:\n",
    "- p2: Trained policy network (neural network weights)\n",
    "- fin_opt_state: Final optimizer state (momentum/variance accumulators)\n",
    "- fin_keys: Final random keys after training\n",
    "- losses: List of total loss values per iteration\n",
    "- ref_losses: Reference tracking error per iteration\n",
    "- eff_losses: Efficiency (copper loss) per iteration\n",
    "- i_lim_losses: Current limit constraint violation per iteration\n",
    "- i_ss_losses: Steady-state error per iteration\n",
    "- acts_norm_losses: Action magnitude penalty per iteration\n",
    "- train_data: Intermediate training trajectories for analysis\n",
    "\"\"\"\n",
    "\n",
    "# Train DPC policy on PMSM environment\n",
    "(p2, fin_opt_state, fin_keys, losses, ref_losses, eff_losses,\n",
    " i_lim_losses, i_ss_losses, acts_norm_losses, train_data) = trainer.fit_non_jit(\n",
    "    policy,              # Initial policy network\n",
    "    motor_env,           # PMSM motor simulator\n",
    "    keys,                # Random keys for sampling\n",
    "    opt_state            # Initial optimizer state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize training convergence by plotting loss components.\n",
    "\n",
    "This generates diagnostic plots showing:\n",
    "1. Total loss convergence\n",
    "2. Reference tracking error decay (primary objective)\n",
    "3. Efficiency loss trajectory (copper loss minimization)\n",
    "4. Current limit constraint violations\n",
    "5. Steady-state error evolution\n",
    "6. Action magnitude penalties\n",
    "\n",
    "Interpretation:\n",
    "- All losses should decrease monotonically (no guarantee due to non-convex problem)\n",
    "- Reference loss should show fastest initial decay\n",
    "- Efficiency loss may oscillate due to trade-offs with tracking\n",
    "- Current limit loss indicates policy constraint satisfaction\n",
    "\"\"\"\n",
    "\n",
    "# Plot all loss components during training\n",
    "plot_training_losses(\n",
    "    losses,              # Total weighted loss\n",
    "    ref_losses,          # Torque reference tracking error\n",
    "    eff_losses,          # Efficiency (copper loss) I²R\n",
    "    i_lim_losses,        # Current limit constraint\n",
    "    i_ss_losses,         # Steady-state error\n",
    "    acts_norm_losses     # Action magnitude penalty\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPC_w_Jax_github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
